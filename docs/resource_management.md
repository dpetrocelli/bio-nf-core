# Gesti√≥n de Recursos: CPU, Memoria y GPU

## üéØ Configuraci√≥n de Recursos por Escenario

| Escenario | Comando | CPU | RAM | Tiempo |
|-----------|---------|-----|-----|---------|
| **üíª Laptop** | `-profile laptop,docker` | 4 cores | 8GB | 4h |
| **üñ•Ô∏è Desktop** | `-profile docker` | 8 cores | 16GB | 8h |
| **üè¢ Servidor** | `-profile server,docker` | 32 cores | 128GB | 48h |
| **üå©Ô∏è HPC** | `-profile hpc` | 64 cores | 500GB | 7 d√≠as |
| **‚ö° GPU** | `-profile gpu,docker` | + GPU | +16GB | Acelerado |

## ‚öôÔ∏è Configuraci√≥n Autom√°tica por Proceso

Los procesos se clasifican autom√°ticamente usando **labels**:

```nextflow
process ANALYZE_COMPOSITION {
    label 'process_medium'  // 6 CPU, 36GB RAM, 8h
    
    script:
    """
    # An√°lisis computacionalmente intensivo
    """
}
```

### Labels Disponibles:

| Label | CPU | Memoria | Tiempo | Uso |
|-------|-----|---------|---------|-----|
| `process_single` | 1 | 6GB | 4h | Validaci√≥n, conteos simples |
| `process_low` | 2 | 12GB | 4h | An√°lisis b√°sicos |
| `process_medium` | 6 | 36GB | 8h | Bioinform√°tica est√°ndar |
| `process_high` | 12 | 72GB | 16h | An√°lisis pesados |
| `process_high_memory` | 12 | 200GB | 16h | Genomas grandes |
| `process_gpu` | 6 + GPU | 16GB | 8h | Machine Learning |

## üöÄ Ejemplos Pr√°cticos

### 1. Ejecuci√≥n en Laptop (Recursos Limitados)
```bash
# Reduce autom√°ticamente recursos
nextflow run main.nf -profile laptop,docker --input "data/*.fasta"

# Recursos m√°ximos: 4 CPU, 8GB RAM, 4h
```

### 2. Ejecuci√≥n en Servidor (M√°s Potencia)
```bash
# Usa m√°s recursos disponibles
nextflow run main.nf -profile server,docker --input "data/*.fasta"

# Recursos m√°ximos: 32 CPU, 128GB RAM, 48h
```

### 3. Ejecuci√≥n con GPU (Machine Learning)
```bash
# Habilita GPU para procesos compatibles
nextflow run main.nf -profile gpu,docker --input "data/*.fasta"

# Requiere: NVIDIA Docker runtime
```

### 4. L√≠mites Personalizados
```bash
# Override manual de recursos
nextflow run main.nf -profile docker \\
    --max_cpus 16 \\
    --max_memory 64.GB \\
    --max_time 12.h \\
    --input "data/*.fasta"
```

## üîß Configuraci√≥n Avanzada

### Para HPC/SLURM:
```bash
nextflow run main.nf -profile hpc \\
    -with-report execution_report.html \\
    -with-timeline timeline.html \\
    -with-trace trace.txt
```

### Para AWS Batch:
```bash
nextflow run main.nf -profile cloud \\
    --workDir s3://my-bucket/work \\
    --outdir s3://my-bucket/results
```

## üìä Monitoreo de Recursos

### Reportes Autom√°ticos
Cada ejecuci√≥n genera:

```
results/pipeline_info/
‚îú‚îÄ‚îÄ execution_report.html    # üìä Uso de recursos por proceso
‚îú‚îÄ‚îÄ execution_timeline.html  # ‚è±Ô∏è Timeline de ejecuci√≥n  
‚îî‚îÄ‚îÄ execution_trace.txt      # üìù Logs detallados
```

### M√©tricas Importantes:
- **Peak RSS**: Memoria m√°xima real usada
- **%CPU**: Utilizaci√≥n de CPU
- **Duration**: Tiempo total vs tiempo de CPU
- **Exit status**: C√≥digos de error

## üê≥ Docker + Recursos

### Configuraci√≥n de Docker:
```bash
# Limitar recursos en Docker
docker run --cpus="4" --memory="8g" --gpus all my-pipeline
```

### Nextflow maneja autom√°ticamente:
- CPU assignment por contenedor
- Memory limits
- GPU access (`--gpus all` cuando se necesita)
- User permissions (`-u $(id -u):$(id -g)`)

## ‚ö° Optimizaci√≥n de Performance

### 1. Paralelizaci√≥n Inteligente
```nextflow
// Nextflow paraleliza autom√°ticamente
Channel.fromPath("*.fasta")
    .map { [meta, file] }
    .set { samples }

PROCESS(samples)  // Ejecuta en paralelo para cada muestra
```

### 2. Resource Scaling on Retry
```nextflow
process HEAVY_ANALYSIS {
    memory { 8.GB * task.attempt }  // Dobla memoria en retry
    time   { 4.h  * task.attempt }  // Dobla tiempo en retry
    
    errorStrategy 'retry'
    maxRetries 2
}
```

### 3. Queue Management
```nextflow
process {
    withLabel: process_high {
        queue = 'highmem'      // Cola espec√≠fica HPC
        time = '72.h'          // Tiempo extendido
        memory = '500.GB'      // Memoria extra
    }
}
```

## üõ†Ô∏è Troubleshooting Recursos

### Error: "Out of Memory" 
```bash
# Ver uso real en el reporte
cat results/pipeline_info/execution_trace.txt | grep FAILED

# Aumentar memoria
nextflow run main.nf --max_memory 32.GB
```

### Error: "Time Limit Exceeded"
```bash
# Ver procesos lentos
grep "duration" results/pipeline_info/execution_trace.txt

# Aumentar tiempo l√≠mite  
nextflow run main.nf --max_time 24.h
```

### Error: "CPU Oversubscription"
```bash
# Limitar CPU paralelos
nextflow run main.nf --max_cpus 8

# O usar profile espec√≠fico
nextflow run main.nf -profile laptop
```

## üìà Escalado para Producci√≥n

### Datos Peque√±os (< 1GB)
```bash
nextflow run main.nf -profile laptop,docker
```

### Datos Medianos (1-100GB)  
```bash
nextflow run main.nf -profile server,docker
```

### Datos Grandes (> 100GB)
```bash
nextflow run main.nf -profile hpc
# O cloud con auto-scaling
nextflow run main.nf -profile cloud
```

Los perfiles de recursos se ajustan autom√°ticamente seg√∫n el entorno y datos, garantizando uso √≥ptimo de recursos disponibles.